{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Dense, Input, Dropout, Bidirectional, LSTM, Embedding\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_tOlRoBf.csv',\n",
       " 'SentimentAnalysis-Copy1.ipynb',\n",
       " 'SentimentAnalysis.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'submission.csv',\n",
       " 'train_F3WbcTw.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_F3WbcTw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
       "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
       "      <td>I can completely understand why you’d want to ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
       "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
       "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
       "      <td>ocrevus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
       "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0   \n",
       "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4   \n",
       "2  fe809672251f6bd0d986e00380f48d047c7e7b76   \n",
       "3  bd22104dfa9ec80db4099523e03fae7a52735eb6   \n",
       "4  b227688381f9b25e5b65109dd00f7f895e838249   \n",
       "\n",
       "                                                text        drug  sentiment  \n",
       "0  Autoimmune diseases tend to come in clusters. ...     gilenya          2  \n",
       "1  I can completely understand why you’d want to ...     gilenya          2  \n",
       "2  Interesting that it only targets S1P-1/5 recep...  fingolimod          2  \n",
       "3  Very interesting, grand merci. Now I wonder wh...     ocrevus          2  \n",
       "4  Hi everybody, My latest MRI results for Brain ...     gilenya          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Frame is  (5279, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Data Frame is ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3825\n",
       "1     837\n",
       "0     617\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_train = list(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "# reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "no_stop_words = remove_stop_words(reviews_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews = get_stemmed_text(reviews_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no_stop_words = remove_stop_words(stemmed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews = get_lemmatized_text(reviews_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "        text = str(sentence)\n",
    "        text = text.replace('.', \" . \")\n",
    "        text = text.replace('\"', '')\n",
    "        text = text.replace('”', '')\n",
    "        text = text.replace('“', '')\n",
    "        text = text.replace('%', ' % ')\n",
    "        text = text.replace('®', ' ® ')\n",
    "        text = text.replace('$', ' $ ')\n",
    "        text = text.replace(\"'\", '')\n",
    "        text = text.replace('/', \" / \")\n",
    "        text = text.replace('-', ' - ')\n",
    "        text = text.replace('&', ' & ')\n",
    "        text = text.replace('?', \" ? \")\n",
    "        text = text.replace(',', \" , \")\n",
    "        text = text.replace(':', \" : \")\n",
    "        text = text.replace(';', \" ; \")\n",
    "        text = text.replace('(', \" ( \")\n",
    "        text = text.replace(')', \" ) \")\n",
    "        text = text.replace('[', \" [ \")\n",
    "        text = text.replace(']', \" ] \")\n",
    "#         text = text.replace('_',' _ ')\n",
    "        text = text.replace('+',' + ')\n",
    "        text = text.replace('⃝','')\n",
    "        # text = text.replace('\\uf0a3', \"\")\n",
    "        # text = text.replace('\\uf072','')\n",
    "        text = text.replace('…',' … ')\n",
    "        # text = text.replace('\\uf06d','')\n",
    "        text = text.replace(' ','')\n",
    "        text = text.replace('','')\n",
    "        # text = text.replace('\\uf0a4','')\n",
    "        text = text.replace('','')\n",
    "        # text = text.replace('\\uf052','')\n",
    "        text = text.replace('\\t', \" \")\n",
    "        text = text.replace('\\n', \" \")\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autoimmune diseases tend to come in clusters as for gilenya – if you feel good don’t think about it it won’t change anything but waste your time and energy i’m taking tysabri and feel amazing no symptoms other than dodgy color vision but i’ve had it since always so don’t know and i don’t know if it will last a month a year a decade ive just decided to enjoy the ride no point in worrying'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/anaconda3/envs/corgen/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/ai/anaconda3/envs/corgen/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai/anaconda3/envs/corgen/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7143939393939394\n",
      "Accuracy for C=0.05: 0.7212121212121212\n",
      "Accuracy for C=0.25: 0.7196969696969697\n",
      "Accuracy for C=0.5: 0.7212121212121212\n",
      "Accuracy for C=1: 0.7196969696969697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "target = y\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_ngram = LogisticRegression(C=0.5)\n",
    "final_ngram.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "# ngram_vectorizer.fit(reviews_train_clean)\n",
    "# X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "# # X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "# target = y\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, target, train_size = 0.90\n",
    "# )\n",
    "\n",
    "# for c in [0.001,0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#     svm = LinearSVC(C=c)\n",
    "#     svm.fit(X_train, y_train)\n",
    "#     print (\"Accuracy for C=%s: %s\" \n",
    "#            % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# # Accuracy for C=0.01: 0.89104\n",
    "# # Accuracy for C=0.05: 0.88736\n",
    "# # Accuracy for C=0.25: 0.8856\n",
    "# # Accuracy for C=0.5: 0.88608\n",
    "# # Accuracy for C=1: 0.88592\n",
    "    \n",
    "# final_svm_ngram = LinearSVC(C=0.01)\n",
    "# final_svm_ngram.fit(X, target)\n",
    "# # print (\"Final Accuracy: %s\" \n",
    "# #        % accuracy_score(target, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/anaconda3/envs/corgen/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.001: 0.7575757575757576\n",
      "Accuracy for C=0.005: 0.7613636363636364\n",
      "Accuracy for C=0.01: 0.7651515151515151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/anaconda3/envs/corgen/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.05: 0.7443181818181818\n",
      "Accuracy for C=0.1: 0.7386363636363636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(lemmatized_reviews)\n",
    "X = ngram_vectorizer.transform(lemmatized_reviews)\n",
    "# X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "target = df['sentiment'].astype(str)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.9\n",
    ")\n",
    "\n",
    "for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "\n",
    "final = LinearSVC(C=0.01)\n",
    "final.fit(X, target)\n",
    "# print (\"Final Accuracy: %s\" \n",
    "#        % accuracy_score(target, final.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_list = [len(clean_sentence(item).split()) for item in list(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.median(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = statistics.median(len_list)#max(len(clean_sentence(item).split()) for item in list(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean sentences in text\n",
    "df['text'] = df['text'].apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_hash', 'text', 'drug', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['fulltext'] = no_stop_words #df['drug'] + ' ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "# max_len = 80#int(np.mean(h))\n",
    "print('preprocessing data...')\n",
    "tokenizer = Tokenizer()#num_words= vocabulary_size\n",
    "\n",
    "tokenizer.fit_on_texts(df['fulltext'])\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "sentences = tokenizer.texts_to_sequences((df['fulltext']))\n",
    "X_sentences = pad_sequences(sentences, maxlen=max_len, padding='post', truncating = 'post')\n",
    "\n",
    "# X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "# # y_train = np.asarray(pd.get_dummies(y))\n",
    "y = to_categorical(le.transform(y), num_classes=None)\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of questions tensor: (5279, 166)\n",
      "Shape of label tensor: (5279, 3)\n",
      "num_classes :  3\n"
     ]
    }
   ],
   "source": [
    "print('Shape of questions tensor:', X_sentences.shape)\n",
    "#print('Shape of instructions tensor:', X_tags.shape)\n",
    "print('Shape of label tensor:', y.shape)\n",
    "num_classes = len(le.classes_)\n",
    "print('num_classes : ', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sentences, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_tOlRoBf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>On fingolimod and have been since December 201...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
       "      <td>humira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
       "      <td>tagrisso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
       "      <td>stelara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08   \n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a   \n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7   \n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae   \n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f   \n",
       "\n",
       "                                                text        drug  \n",
       "0  256 (previously stable on natalizumab), with 5...  fingolimod  \n",
       "1  On fingolimod and have been since December 201...  fingolimod  \n",
       "2  Apparently it's shingles! :-/ I do have a few ...      humira  \n",
       "3  If the Docetaxel doing once a week x3 weeks th...    tagrisso  \n",
       "4  CC, Stelara worked in a matter of days for me....     stelara  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2924, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_test = list(test_df['text'])\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
    "X_test = ngram_vectorizer.transform(lemmatized_reviews_test)\n",
    "preds = final.predict(X_test)\n",
    "# print (\"Final Accuracy: %s\" % accuracy_score(target, final_ngram.predict(X_test)))\n",
    "# no_stop_words_test = remove_stop_words(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_test = list(test_df['text'])\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
    "# lemmatized_reviews_test = get_s(no_stop_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df['fulltext'] = no_stop_words_test#test_df['drug'] + ' '+ test_df['text']\n",
    "sentences_test = tokenizer.texts_to_sequences((test_df['fulltext']))\n",
    "X_sentences_test = pad_sequences(sentences_test, maxlen=max_len, padding='post', truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = list(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_list = [le.inverse_transform([np.argmax(pred, axis = -1)])[0] for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for _ind in range(len(test_df)):\n",
    "#     p = np.argmax(pred, axis = -1)\n",
    "#     sentiment = le.inverse_transform([p[0]])\n",
    "#     test_df.loc[_ind, 'sentiment'] = sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['sentiment'] = label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>On fingolimod and have been since December 201...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
       "      <td>humira</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
       "      <td>tagrisso</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
       "      <td>stelara</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08   \n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a   \n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7   \n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae   \n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f   \n",
       "\n",
       "                                                text        drug sentiment  \n",
       "0  256 (previously stable on natalizumab), with 5...  fingolimod         2  \n",
       "1  On fingolimod and have been since December 201...  fingolimod         2  \n",
       "2  Apparently it's shingles! :-/ I do have a few ...      humira         2  \n",
       "3  If the Docetaxel doing once a week x3 weeks th...    tagrisso         2  \n",
       "4  CC, Stelara worked in a matter of days for me....     stelara         2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_hash', 'text', 'drug', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2716\n",
       "1     131\n",
       "0      77\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = test_df[['unique_hash', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('submission.csv', index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python[corgen]",
   "language": "python",
   "name": "corgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
